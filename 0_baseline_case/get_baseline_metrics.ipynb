{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf5c5ea-d97b-4c1f-94c8-43b91364aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "flag_remove_extremes:  False\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules:\n",
    "from astropy.io import fits\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Flag to remove the young and old clusters:\n",
    "flag_remove_extremes = False # Currently removing younger than 10^7 years and older than 10^9.5\n",
    "\n",
    "# Flag to augment or not:\n",
    "flag_use_augmented = False\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Directories:\n",
    "\n",
    "# Raw data:\n",
    "dir_data_raw = \"/pool001/vianajr/cluster_ages_1/data/data_raw/raw_phangs_dataset.h5\"\n",
    "\n",
    "# Results parent directory:\n",
    "dir_results_parent = \"/pool001/vianajr/cluster_ages_1/results/baseline/\"\n",
    "\n",
    "# Aux text:\n",
    "txt_remextremes = \"yes\" if flag_remove_extremes else \"no\"\n",
    "# Base prefix for the results directory:\n",
    "results_prefix = f\"baseline_remextremes_{txt_remextremes}\"\n",
    "\n",
    "# Create the folder for these results:\n",
    "dir_top_results = dir_results_parent + results_prefix \n",
    "\n",
    "# Create if not exists:\n",
    "if not os.path.exists(dir_top_results): os.makedirs(dir_top_results)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Display:\n",
    "\n",
    "print()\n",
    "print(\"--------------------------------------\")\n",
    "print(\"flag_remove_extremes: \", flag_remove_extremes)\n",
    "print(\"--------------------------------------\")\n",
    "print()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Set the seed for reproducibility\n",
    "random_seed = 15\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)  # If you also want to ensure reproducibility with numpy functions\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Class to read the dataset in the format it is:\n",
    "class ReadPhangsH5:\n",
    "    \n",
    "    def __init__(self, hdf5_filename):\n",
    "        # loading from hdf5 file\n",
    "        with h5py.File(hdf5_filename, \"r\") as hf:\n",
    "            \n",
    "            # Get the cluster ID:\n",
    "            self.cluster_ids = np.array(hf[\"cluster_ids\"], dtype=np.int32)\n",
    "            # Use astype(str) to correctly convert HDF5 string datasets to Python strings, for the galaxy_ids:\n",
    "            self.galaxy_ids = np.array(hf[\"galaxy_ids\"]).astype(str)\n",
    "            # Get the image cutouts:\n",
    "            self.image_cutouts = np.array(hf[\"image_cutouts\"], dtype=np.float32)\n",
    "            # Get the log of the ages:\n",
    "            self.cluster_log_ages = np.array(hf[\"cluster_log_ages\"], dtype=np.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the image cutouts for the instance (5 images)\n",
    "        x = self.image_cutouts[index]\n",
    "\n",
    "        # Take the mean of the 5 images along the first dimension (channel dimension)\n",
    "        x_mean = np.mean(x, axis=0)  # Shape will now be (112, 112)\n",
    "\n",
    "        # Get the log of the ages:\n",
    "        y = self.cluster_log_ages[index]\n",
    "\n",
    "        return x_mean, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_cutouts)\n",
    "\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Function to split the input (X) and output (Y) from the dataset\n",
    "def separate_X_Y(dataset):\n",
    "    X = [x for x, _ in dataset]\n",
    "    Y = [y for _, y in dataset]\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Define a function to split the data into tr, vl, and ts sets\n",
    "def split_dataset(N, tr_ratio=0.7, vl_ratio=0.15, seed=42):\n",
    "    \n",
    "    # Initialize:\n",
    "    random.seed(seed)\n",
    "    indices = list(range(N))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    tr_split = int(tr_ratio * N)\n",
    "    vl_split = int((tr_ratio + vl_ratio) * N)\n",
    "    \n",
    "    tr_indices = indices[:tr_split]\n",
    "    vl_indices = indices[tr_split:vl_split]\n",
    "    ts_indices = indices[vl_split:]\n",
    "    \n",
    "    return tr_indices, vl_indices, ts_indices\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84001f24-3776-4ece-b9d4-53325f601187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom median absolute error metric using numpy\n",
    "def custom_median_absolute_error(dnrm_y_pred, dnrm_y_true):\n",
    "    \n",
    "    # Convert tensors to numpy arrays\n",
    "    abs_diff = np.abs(dnrm_y_true - dnrm_y_pred)\n",
    "    # Use numpy to calculate the median and multiply by 1.49\n",
    "    median_abs_diff = np.median(abs_diff)  \n",
    "    return 1.49 * median_abs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567208c2-77fc-4778-8e3c-acc984a71c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Start running the code\n",
    "\n",
    "# Create an instance of the dataset class\n",
    "raw_dataset = ReadPhangsH5(dir_data_raw)\n",
    "\n",
    "# Get X and Y:\n",
    "raw_X, raw_Y = separate_X_Y(raw_dataset)\n",
    "# Display:\n",
    "print(\"X.shape: \", raw_X.shape)\n",
    "print()\n",
    "\n",
    "# Get the list of cluster ids and galaxy ids:\n",
    "raw_clust_ids = raw_dataset.cluster_ids\n",
    "raw_galax_ids = raw_dataset.galaxy_ids\n",
    "    \n",
    "# Remove instances where Y is less than 7 or bigger than 9.5 if flag_remove_extremes is True\n",
    "if flag_remove_extremes:\n",
    "    \n",
    "    # Mask:\n",
    "    mask = (raw_Y >= 7) & (raw_Y <= 9.5)\n",
    "    \n",
    "    # Apply mask to get the curated sets:\n",
    "    cur_X = raw_X[mask]\n",
    "    cur_Y = raw_Y[mask]\n",
    "    # Update the ids:\n",
    "    cur_clust_ids = raw_clust_ids[mask]\n",
    "    cur_galax_ids = raw_galax_ids[mask]\n",
    "    \n",
    "    # Display:\n",
    "    print(\"New X.shape after removing young clusters: \", cur_X.shape)\n",
    "    print()\n",
    "    \n",
    "# Otherwise simple assignation:\n",
    "else:\n",
    "    cur_X = raw_X\n",
    "    cur_Y = raw_Y\n",
    "    \n",
    "# Get tr, vl, and ts indices\n",
    "tr_indices, vl_indices, ts_indices = split_dataset(len(cur_Y))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Get the X_tr, X_vl, X_ts using the indices:\n",
    "X_tr = cur_X[tr_indices]\n",
    "X_vl = cur_X[vl_indices]\n",
    "X_ts = cur_X[ts_indices]\n",
    "\n",
    "# Get the Y_tr, Y_vl, Y_ts using the indices:\n",
    "Y_tr = cur_Y[tr_indices]\n",
    "Y_vl = cur_Y[vl_indices]\n",
    "Y_ts = cur_Y[ts_indices]\n",
    "\n",
    "# Display shapes:\n",
    "print(\"Tr. set shapes: \", X_tr.shape, Y_tr.shape)\n",
    "print(\"Vl. set shapes: \", X_vl.shape, Y_vl.shape)\n",
    "print(\"Ts. set shapes: \", X_ts.shape, Y_ts.shape)\n",
    "print()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Now get the mean output of the training set:\n",
    "mean_train_output = np.mean(Y_tr)\n",
    "print(\"Mean of training set (log age): \", mean_train_output)\n",
    "print()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Use this mean as a prediction for all, the training, the validation and the test sets:\n",
    "Y_pred_tr = np.full_like(Y_tr, mean_train_output)\n",
    "Y_pred_vl = np.full_like(Y_vl, mean_train_output)\n",
    "Y_pred_ts = np.full_like(Y_ts, mean_train_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c46f53-2418-442a-8de4-0ed3f93eb2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Median Absolute Error - Tr. set: 1.2200055646896362\n",
      "Custom Median Absolute Error - Vl. set: 1.0720550966262816\n",
      "Custom Median Absolute Error - Ts. set: 1.2200055646896362\n",
      "\n",
      "Results saved at: /pool001/vianajr/cluster_ages_1/results/baseline/baseline_remextremes_no/baseline_dex_results.pkl\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Get the custom_median_absolute_error of each set:\n",
    "dex_tr = custom_median_absolute_error(Y_pred_tr, Y_tr)\n",
    "dex_vl = custom_median_absolute_error(Y_pred_vl, Y_vl)\n",
    "dex_ts = custom_median_absolute_error(Y_pred_ts, Y_ts)\n",
    "\n",
    "# Display errors:\n",
    "print(\"Custom Median Absolute Error - Tr. set:\", dex_tr)\n",
    "print(\"Custom Median Absolute Error - Vl. set:\", dex_vl)\n",
    "print(\"Custom Median Absolute Error - Ts. set:\", dex_ts)\n",
    "print()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Save the custom_median_absolute_error of each set:\n",
    "results_dex = {\n",
    "    \"dex_tr\": dex_tr,\n",
    "    \"dex_vl\": dex_vl,\n",
    "    \"dex_ts\": dex_ts,\n",
    "    \"mean_train_output\": mean_train_output\n",
    "}\n",
    "\n",
    "# Save results as pickle file\n",
    "results_path = os.path.join(dir_top_results, \"baseline_dex_results.pkl\")\n",
    "with open(results_path, \"wb\") as f:\n",
    "    pickle.dump(results_dex, f)\n",
    "\n",
    "print(f\"Results saved at: {results_path}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0dc58-d75e-4e9c-b381-72490d949caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61c09a40-549e-4d2f-9d5c-0780565301e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187957"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(np.abs((Y_tr-Y_pred_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8a81775-c73b-47a9-921d-cda8b5a72e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187957"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(np.abs((Y_ts-Y_pred_ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38028fed-fe7e-4dc8-bf01-ec3da1a8311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad478fc2-371a-4072-8fc9-7248b23fa428",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_dex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52961b-96ef-4298-a340-44c273e2544b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
